{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABYNklEQVR4nO29e3RcxZkv+itZNkKykWwJy+CWZHKSXIkBS0nLEmQuNiySgZkzQJiTnBkiOGSSOZ44sdSWmTmXewyWmBnumhCNJRkwOayQjI2UkMfcdQ6cPCdJQ5IJj5ETOSTRZZIJ2HIgGBubWDiApa77R3Vp165dtffud+/W91urVvfeXbt27eru76vvzTjnIBAIBALBhqpST4BAIBAI5Q1iFAQCgUDwBTEKAoFAIPiCGAWBQCAQfEGMgkAgEAi+qC71BPKNpqYmvmHDhsB+r7/+Ourq6go/oQiB1sQMWhcvaE28iPqaHDx48Djn/HzTZxXHKDZs2ICpqanAfo8//jiuvPLKwk8oQqA1MYPWxQtaEy+iviaMscO2z0j1RCAQCARfEKMgEAgEgi+IURAIBALBFxVnoyAQCIRS4ezZszh69CjeeOONUk/FipqaGsRiMSxfvjz0NcQoCARCtMA5wJj9uIQ4evQoVq1ahQ0bNoCVyZxUcM5x4sQJHD16FBdddFHo60j1RCAQooPhYWBwUDAHQLwODorzZYA33ngDjY2NZckkAIAxhsbGxowlHmIUBAIhGuAcOHUKGB93mMXgoDg+dcphHiVGuTIJiWzmR6onAoEQDTAGjI6K9+PjogFAIiHOlzmBjjJIoiAQCNGByiwkiEm48JGPfARr167FJZdckrcxiVEQCIToQKqbVKg2CwI+/OEP4xvf+EZexyRGQSAQogHVJpFIAKmUeFVtFhHD5CSwYQNQVSVeJydzH3Pz5s1Ys2ZN7gMpIBsFgUCIBhgDGhrcNgmphmpoiJz6aXIS2LoVOHNGHB8+LI4BoK+vdPMygRgFgUCIDoaH3XETkllEjEkAwK5dDpOQOHNGnC83RkGqJwKBEC3oTCGCTAIAjhzJ7HwpQYyCQMgHdP14BPXlhOKitTWz86UEMQoCIVeUebQwoTxx991Aba37XG2tOJ8LbrrpJlx++eV47rnnEIvF8NBDD+U2IMhGQSDkBjVaGBD6ctUzp4zyEBHKC9IOsWuXUDe1tgomkat94gtf+ELuk9NQUkbBGLsWwDiAZQA+wzn/e+3zcwAcABAHcALAn3LOXyj2PAkEKyhamJAD+vrKz3BtQslUT4yxZQDuB/CHAC4GcBNj7GKt20cBnOScvx3AKIBPFneWBEIIULQwocJRShtFD4Bfcs5/xTl/C8AjAG7Q+twAYH/6/VcAXM3KPeMWYemBooUJFY5Sqp7WA5hVjo8C6LX14ZzPM8ZeA9AI4LjaiTG2FcBWAGhubsbjjz8eePO5ublQ/ZYSaE3MCFyX2VmgpQU4cEC8zs4Cx44BExPiuAJBvxUv5ubmUF9fj9OnT5d6KoF44403Mvr+KsKYzTl/EMCDANDd3c2vvPLKwGsef/xxhOm3lEBrYkbgugwPC4P2zp1C3SQljNOngVtuKdIsiwv6rXjx+OOPo6amBqtWrSr1VAJRU1ODd73rXaH7l5JR/BqAut2Kpc+Z+hxljFUDqIcwahMI5YNiRguXcXU3QuWilIziXwG8gzF2EQRD+DMAH9L6PArgVgBPAvgAgO9yTopfQhkiKFo4HwReSi6SCUnJpaGBYjYILmzYsAGrVq3CsmXLUF1djampqZzGKxmjSNsctgP4JoR77Gc55z9jjP0NgCnO+aMAHgLwMGPslwBehWAmBEK0kA8CT/EalYkCSojJZBJNTU15GaukNgrO+dcAfE07t1t5/waADxZ7XgRC3pAvAk/xGpWHCEmIlMKDQCgkJIGXdROqqhwmkSmBp3iNykGB638zxvAHf/AHiMfjePDBB3OeLjEKAqHQyBeBp3iNykE+NxAG/OAHP8CPfvQjfP3rX8f999+P733vezmNR4yCQCg08kHgK7C625JHASXE9evXAwDWrl2LG2+8Ec8880xO4xGjIBAKiXwReFt1t0QiktXdCCiYhPj6668vBv29/vrr+Na3voVLLrkkpzErIuCOQChb5LN8ZwVVd1vy0DcQqpMDkNP3+vLLL+PGG28EAMzPz+NDH/oQrr322pymS4yCQCg08kngK6S625JHAet/v+1tb8OhQ4fyMk0JYhQEQjFABJ6gI0ISItkoCARC5SEqpWkjsoEgRkEgECoLhS5NG8CEyj3LUDbzI0ZBIBDKC7lIAwUOZAtiQjU1NThx4kTZMgvOOU6cOIGampqMriMbBYFAKB/kmtaikKlOgtKxAIjFYjh69CheeeWV7O9TYNTU1CAWi2V0DTEKAmEpIArpyfOdF0uOI8fK9XmDmNATT2D58uW46KKLcrtPGYJUTwRCpaNQOvt8G4zzldYi20C2MM+zRPNtEaMgECoZmerswxL/l14qDPPJlRBnGwkflpku0XxbxCgIhEqDSrQYA/bsCbdLz4RYzs8XxmCcKyHOJtVJWGYaxIQqGZzzimrxeJyHQTKZDNVvKYHWxIxIrcvQEOeJBOeplDhOpcTx7t2cC1InmvxcQvYDnOv1YwXJZNL5XDZDv4yQ4RwCx/I79ru33/PY1ndoKFq/EwMgCsYZ6WrJCXu+GzGK7EFrYkZk1sWP0HZ1BRPBsMSSp9cklfJnPtnAhxAXHGGfx8KEIvM7scCPUZDqiUCICniA/cBmDO7qAqang3X2mdoHCqGrHx5231POqdAV33gGKq+IRFPnE8QoCIQoIKz9wETsr78+nM4+LLHkHJidLVxtjGITYvncVOvDCoqjIBDKHTxEfAEgCGoqBezc6b7+tdeEQdsv+ZxOLP3SXjMGVFcXJPNpSVDATK6VAmIUBEK5gzGgvl6okNRAr64ucf6uuwQjOe884LHHhJqpq0tIEo8+aif2+j0yIZYXXGBWEUWVqEYok2spQIyCQCh3cC6kgulp9/npaWDzZvF+717HFtHU5PSVTKO+PpjoZUosK01XX2nPk0cQoyAQyh0yFuKJJ9zMoqvLIeSMOZLD8ePiVRqw9+wRhu2w9/I7JixJkDGbQCh3cC7sDiaJQtojdAO2xOhoeCZBIFhAvyACodyh2ihUSJUSYI8MJq+d6BQxKmMQoyAQygkmoqbaKFT3zelpYcTescOJlwDcr2FcPCuZkBa6iFGhUSbfDdkoCIRygV8tBj+PJEB8Vl8PbNkibBLyui1bnD6Z3jMqxNSGMG7F5WyDKaPvhhgFgVAOCCJqkjHYPJIk0eNcuMsCbmJiIjB+9xwYcBPSciKq+lxscytkEaNCo9yYnC23R1Qb5XrKHrQmZhRtXTLItRRqjDCJ9Uz37O3lfGDAN99SyX4r2eSCKkROKgPyvib5+D1kAFCuJwIhAshHUZxMi/+Y7tnbK+Iy8plCPB+6dnWXHXZumeRwKjeUUZEkYhQEQrkgX0QtiMCo45nuCQjVUy5V5lTky6Asn0uf28CAeW5Rz+FURkyOGAWBUChksovOJ1EzEZgdOxwFxuAgMDTkvufAALCwIO65d693zGyZRDZSgB+k/SXM+WyKGJULyozJkTGbQJAIayQNA91jRSbrkwZlfex8JabTiT8gCP/evc49ZbqP3bvF2AMDwFNPAe95D/DDH4p+Tz/tHndw0GtQl/fzm1s+DcqcAydPehnZ3r1e47tEtjmc8vlbyAZllqiwJIyCMbYGwBcBbADwAoD/zDk/qfXpAvAAgPMALAC4m3P+xaJOlLB04OeKeOWVmY2le6zU14vkfGochGQaQ0POn354WHyWS2I6ncBI7N0L3HuveC9zQnV3i8SBnAPPPCM+27FDjCEZhWQ24+OCmfT2AmNjznMODjqJCdXn15ng6KizHoB7nQtN9DJNS1IubqnllKjQZuUuZANwD4Db0+9vB/BJQ593AnhH+v2FAF4C0BA0Nnk9ZY8luyYBnkJZrYvJY6Wri/OFBee8ybtoYMDtwRNU0jNMFbaFBfc85ue9Fe8GBkTTz6VSzrx6e91rolbPW1hwP7f+DCbvHbkWQ0P+z6W+HxrivL/fO898VcDLoRxr1P8/KLdSqACeA3BB+v0FAJ4Lcc0hyTj8GjGK7LGk1kT/w6sEXHNFzHpddLdMG2GWBEgSYpVAq0Q3W9dQ/blMTd7P5ka6sOBao+TIiMMk/IiqqRyr/urnjqs/88KCmcnl02U0S7fUqP9//BgFE58XF4yxU5zzhvR7BuCkPLb07wGwH8Dvcc5Ths+3AtgKAM3NzfFHHnkkcA5zc3NYuXJlVvOvVCyZNXnpJWB+Hmhpcc7NzgLLlonPJOJxADmsy+wscOyY+bP02MY+a9eKucnPwh77zUH2OXjQ3G/tWvGqzkVe89JLIoVIXd3iGHOxGFYePSrqUiwsmK+TePFF0Ueds+m+pufSP5uZAc6cAWprgY6OcGuQLdS1kt+XD6L+/7nqqqsOcs67jR/aOEiuDcC3AfzU0G4AcErre9JnnAsgJJDLwtyXJIrssSTWxE+1oO9Us5Uo9HuYdsHqjlvfHdt2stnsdOWO3CQxSZWRek+5O5d9Bwbcqp70c7gkivl5uySi3p9zrxosleJ8927v+nR1ifN+Kjx1TfKlesp2nXn0/z+IquoJwpD9IwAfCDs2MYrssWTWxEZ88mmjMBFoSfxUImyyC9iIrpy73+cmqHNIJDi/80738y4sCPVPb69Z/ZNKeewCyZERrwrJxASDGKZpDYKYqWQS6poEIRPbDtkoyoZRfApuY/Y9hj4rAHwHwI5MxiZGkT2W1JroxEcScAOhzNqYLccaGhLEUN0Fa8bhxXM2YqnOKZOdrjoHfWev7sRTKS8BVo+19UqOjLiN4mFsFLpEoDLMzk5zHx/bUWhkatvJxhbEo///KUdG0ZhmAr9Iq6jWpM93A/hM+v3NAM4CmFZaV9DYxCiyx5JZEz8vHL0fz2JdTITG5M2k9lMZhdzZ67vxTHe6JkOwzhzCzNnAxJIjI+LcnXe6185EVG0Sgc4w9dbfH8yIgpCthBBWAlEQ9f9P2TGKQjZiFNljSaxJFoQjo3XJdHydWPsl4wvLgMLMQ5cWbB5Y/f1utVNvL+c9PY6NYmBASBaqmkp9piApSNoodImis9OZg26TCHIh9vtOspVKQiDq/x9iFAZE/UstBJbMmmSoWsh4XXIhTEE72UwYi0mdpUoBOsMx7ewHBgQhb252MY7kyAjndXWc9/Q495D2BvX+QUwzlXIYkc1mozK13bvdz6xLSX7rmqltJ2j9NUT9/0OMwoCof6mFQOTXJBN1QaEJQLaEKZPxg4jw0JAg5Lo6RxJ9/bogw3p//6ItI3n//d6+ulTCuZcpb97MeVOTYFacC0K/bh3n69ebDdfquqneUbpxPEiNlA3jDtpQaNdH/f9DjMKAqH+phUCk1yRLA2QYFFWiMI1lO/a7j7pTNzVd1dPfH8wo5O4+kXBUT3rzU6+phF2qk9RjqcKyPY/qPab2UVVTft9FpjYKv+uk84OiEkseOJDb7y0Lu0hO12kgRmFApIligRDZNcmWGIREQW0UfvBjfuo5fQcum83t1BT7YNupW1py3z7zZ0HPZxpbZxKZeFABdiYRZh2D5mry2FLn2tW1qMpLjoyYnSLCINs55nGDRIzCgMgSxQIi0mtSQINlxuuSjz+vH8ORdgETIZPpMHbvdt7rhFWN5TDtzE2ShCmOwi8/lB/0oDvpBqvaXFRmp66bfm3Y71mOZzvWoboTm+5nYHjJAwfC20z0uRVC6snwt0+MwoBIE8UCIfJrUiC7QNY2Cr/jsGPoBL2nxxvo1tTEPeok+Vljo5fQbdzoJiYmZtLba1ZHSaI4NubYPyQjUXNV6V5V8lXaJNTxmpvF3DdvdjPA3bvFuLt3i+sXFszeUWEIo415y7HVufqpueRam9YkmczOfdf2XYcZwy+qPUMQozAg8kSxAIj0mpSTRJFP6MxPEm6b+sYvLkElsp2dor+8hykiPJXyqqjSQXbJkRFB4KX00t/vjvDevt1RkSUSnG/Z4g2s6+zk/PzzvURYPptkKPLZJGOqrXW8nySj8SOMfjtvWzoQm4rMwiQWpaxMfnemOJdMNjo2VRxJFMQoConIrkk52SjyCRMhsKW8UImdzlzUa+XOX7rIWgLqFtUrNoli3z5BnBcWhMcSIJiD2v/CC72Mbf16wSB0yaCuzpcI84EBx1tLfRYp/WRDVIOC+Xbvdvc3pWdX7D2LjCKMjUK/n18+MD/YGFoWdhJiFAZEligWEJFek3wZ9Qwqo4Kvizpn+aoSb11FZPJmCjL4qgRWT5+hRoSrx2oacE2yWFyTEIbvRULoNy9dcpHNz3NLzt+PmOp2CZ25mhixbR1VxqKqfPREiWHsNH73MEXh28YgiYIYRbER+TXJ1S5gYTbJz38+H7Pzv6fqbplICH19c7OzW06lBNHs6fHq+CXBMhF5+arv4FVismWL6CeJskydsXKld1zJKA4ccKtMTOPLpq6nH9G3MQK/z3Uma1pbnfHqDMyPkUp9v7quCwuOWk5+FwMD4v+jp2Hx+85N0p9fKhQTimSjoJrZhMpBpiUvVXDuLl86OurUnj5wQHye7xKU6j1ledInnhCvtbWi7sK6dU7p1HvvBZqbgZdfFv2npoDbbnOur68HqqpEGdT6emDLFmDPHnGtPFbrTctSqV1dYozNm0XpU7XP9u3iVdbZvv56UZvi2DGnjrZaBtWEwUFnHiq6uoB//Vdg+XLv+elp8arXx/YbWy1Vqq4t584zAO7yrk884R5P9mlocOZxzjlAT4+4TtarliVgW1uB3/zGf44qTPPSn2dsLFzZU87FdzE9LeY2Nub8Zjdvzu9v1sZBotpIosgeS35NLAbxnNdF7hxNx0GqIr1J11gpgUiffmlzkDUc5Njq/Wy1LvzmIO+lqqEWFpzgsvl5uzSxcaNXwrGobVy7YWmUV6PKbRlm9bH1dbaplkxR3SY1lypN6bU6NDtOaNWT6buwRbYHYWjIXSFQjt3bm7HaFaR68mLJE0UDSr0mExOct7Vxzph4nZgowSR0VUCuNoowf2SbSuYTn3Afb9/uEDlVNaIHgJlcPnXiph+HVQulnyOZTDreTqqRWW3Nzc7ctmxxE0A9Rbn6DFL9s2WLGEOmDtm9W7j7Xnih17PLRlwN3+ci1NTyMoZDZxa24km6ilJlFGGIvGle2djV/GxZGdopiFEYUGqiWI4o5ZpMTAivR/W/U1tbZGZh2YG61iUTu4e+c9R1/bagOVtTmYDNA8dGIFRbiEwMKMdTYyDUuV1yifvcxo2LOvRkMun1ZFL7dnYKQq+umT4nUw0Q6V5rshPojMTGAPy+T5PUofazeRDZ7qdcG9o91m9emdrVwj5nCBCjMIAYhRelXJO2NjNtbGsr0gT0XbckWlAMt9ns+GwupiajqYlQmZiFVM1s2uT93EQI1blIdY68jwy+U5mBnG9NjXf8Cy8UEsWBA/7zlVJAmPVR5yp39H4uoybm6qd2CuMy7Rc3YVJ7GSSzZDIZ7K2U6bxsMM0/iHEGwI9RVOXH0kEg5IYjRzI7n3cwJgyViYRj5O3tFa+vvy5epaHw1CnxdwzC8LAwssrxVIyNCcOzvOf114vXqSlhRLXhxRfFmHv3CkOwjj17HAPm8LCYszrXt94Sr9PT4vUnP3E+274duPJKYNUqoKYGeOMN8/2rqoQxW85XxcKCOH/vvd5765Dro/ZhTKz7+DiwbJkzT/X5du4UnycSwtCfSIhj9X6MOQZxuSZ79jgGat3IW1UlvgMVV1whjMRf/CJw6JBwLJDPNz7uOAmov5nRUXEsjd469N+ZNFr7XWNaN/VZUykgHnf3CVr7TGHjIFFtJFFkjyUtUUjou9KBAXem1DBqBflqU2foO275qu5Qe3u9NgqbhGFSlfjtXG1SgGq0NUkrSlsshWoyFqv5jmxr5Tc/P5dY1ZVYXzdV0st05+5n0Ne/M12yTI+1+P8Ja6PwO/a7zhaol0kMhgEg1ZMXxCi8WPI2ChNSKTej8Pvj6XEY8/Pe3EAqkdaLDqljSPVSGCahEww/byaTwdbEaIaGvIxKUVMlR0a8KTdkdLVkFkGqOtv89OfWCaBUv6ljmOIGwuruTcTXlIbdptJLI+//HxszMT2XLRVJBiBGYQAxCi9KvSZl4fWkIv2HCyVR+O1g1SZtFqrXk75DPnvW6xFkkgI2bXIn4JNjq0RT110HRTpLYm1icgqjMdajWLNGvJpqfvtJFiapRnej1dchrH5fH982j6DgvBDR1nn9/wRlGtCfS0/ZkWcbRckJe74bMYrsQWuiQPVmkcbsTAyVJglC3bHKP7Zf1TbVcK0zB/04lRJERGZ8tSW2k5HEPT2ir75z1qO+m5rEHKS00NnJ+dmz3gp3chyT0TeM+kk21ZWYc69ayZYGPez3ETQfE5MIySzy9v8JUpuFMeZngZwZRaw93himXzk0YhTZg9ZEQ3pX59I9B4n0+k5PJX6qDUANmjMxFFW9ImMx1DoU0o6gpJDwuN5Koq2rbmTmWNlfliY1Ecj5ebc30vr1nN95p0gzrvft6QnvfRNko1B30uoYMt5BJ+BBsSOZSDhqunSVcQQkH8zr/8fG5Ew2iCxtEjrywSh+EWuPfznWHv+jWHuchbmmVI0YRfagNTEglXKvi98f0SZRSCIribkkRLbdoUmVoO6k5XW2lOP6/VXVlGQ4qZQTSyGJ4Py8t36FJJa7d3ttFPq9Oju9qi2bTYBzd3Egzh3pShJ9k7rFtts3BRoGqW9skMxIvU5KaT4oiI3CxHSzfa4A5INRsFh7/H2x9vgXYu3xX8ba4/9PrD3+zjDXFrsRo8getCZmhFqXoB2yLX0G58FV2/yMmJLQ2hiFSoRVQ7ZUUalpMlSCrzIiKckofYyM4txz7c+vEjmTakmVrmw7ZVWy8VMN+Rmdw+64s7iuKBKF/pvIYH5ByKuNItYevyrWHv91rD1+KtYefyLWHr880zEK2YhRZA9aEzNCr4vfTs+2O/QL9LK5guqMwM+tM5FwSw4mryf9WFe59PRwfscdLuO2h1Hoai75/DLSWtf/69HX0lgdpHuXdhj9OdV75GF3nQ2KZqPIA1MwwY9RhMoe29LR3QjgZgC3AHgZQD+ARwF0AfgygIvyF9lBIEQUw8OCbMmgKRlMBYgAKBVq1lMZGHbwoBNM1tUFnHeeyA4qM42OjnoDq+JxcX1/v7ifzH66aZMIrlMz0zY1mbOx6kFee/c6/Xp6gMsuAx57DDh+3P7snItAuWuucY/X2yvGkplmJZ5+WgTUASLYTM1yq0LPoDo0BOzY4b1/T494lUGRiYT7u4gSbEF5QPigvHzDxkHUFmuP/1usPX5nrD0eM3z2f4UZo1iNJIrsQWtiRk7rErQ7VLPAci6O160ThupUyixx1NW5U200N4vdfmurY+SWQSldXR5pwFdtYzIUyx27Yr9IjoxwXlXlllY6O80SkD5//R6mVCY2dYutn58UUiQUxEbhd5xnIA/1KO6YnZn6knqipaP7g7MzU1+enZn6ZP7ZF4FQZtB3p5yLV8acz+Q5eV5C3x3W1zv1I+66y6k3UV8v0oP85jeiyZ2znsbibW8TqTc4BzZuBH7+c2B+XkgMn/qU2MWfOSOOp6e910sMDABPPQU884z7mUz9TJJIKgX87d+K911dwHXXifnLvqrE5AcpWUjJR66VlA4A79rJfnv2OFKVRFAdh3zA9nvIJ3Kpr5JnhM31dLvh3P+dz4kQyhOTk8CGDSIVzoYN4njJ4aWX3LlzOAcuv1y0oSHxWSolji+7TBB4qYaSKidJvDh3is289po4luqm114T/WRhHVUFpGLZMuDSS4FnnxUMY35e5GY6flwU2ZFqJj9VkSwKdNllQm3V0ODkkBoYcHIoBRUOkpiaEs+cSrlzNUnVl4q9e0VeqYUF9/nrrnMz1D17vDmQ7rrLyYsl+11xhXucfOc50mHKtTQ4KH4nQGHvXSrYRA0u1Ep/GGuP3xtrj78ca4/vVdo/xtrjz/hdW6pGqqfsoa9J2abVKCZSKSdTqlRpqKoTW9ZXv0I0QR4tJi8maSzWv5BMmgyeU91q1UJHNrfQ9evd4/T0mI3ZMiivu9t8b6kmk8e6x9W6dSIqXV2jO+80ficuw7WqOiu00dekOpQ1sw8cMOedigiQrddTrD3eGWuP3xprjx9Ov8r2J7H2+Gq/a0vViFFkD31NyiZRX4mRTCbD5STKRF+ue0GpsQ4m/bueDjyo6SnCJYNRA/ZkASBbvIDOFM85Z/G90T1WZwomZtff77jRyvmoXkySmam2CDU+Qvcs27zZCRhU10/WwigELPEyrt9JvhhVEe0UWTMK2WLt8eow/cqhEaPIHvqaMGb+vzNWmvmVCslk0uzeOj8fTLBtTMIUmKfndDLVishFgkhLA3xhwU2c/XbjUsrQUnP4MoowTWUWgKjeZ0ugqMZR6Kks8pQ5NWPovwdkULgoLAoUWGdDLhLFl9Kvz8ba4z9R2rOx9vhP/K4tVSNGkT2WtEThs3NLJpPmCnAyCZ5f0//ofsROtnXrBCHXVVB6ydEgxrFpk5sp6NcHBQKqa6HNxcooli3LjnHYGK8+HzU3lsoQg54hh+/f2NcQu5JRKdQw87Hld1Kj2fOIXBjFBenXNlPzu7ZUrZIZRaGzqy5ZG0VAoNyijcKv6cnwenudc3qNBv1+piA6WyCd3Dlv3+79THWJ1T/bvt1LiHXJwkbkDIQxtEShSw424m5Lfy7dhuU8wqj7MiXUmezcfRh93iUKmy2rQHaQfKie6mLt8ar0+3fG2uPXx9rjy8Nca7wpsAbAPwP4RfrVau8AcB6AowDuCzN2pTKKYhBt05qUXervfCNEFGzy858XKhudGQBCzy8ZQW+vOO7qcgy1nZ1OfiX1HrJegy12QTeES4lGShry83Xr3LEMgDHlBu/sNKfrMO3g9fKkhtKoOaueVGbhFxMh1WdyLv395gy3+jOEJdQhvn8P1BxVii0lOTmZf9WXXyR+ntVr+WAUB2Pt8dpYe3x9rD3+QjpB4GSYa403Be4BcHv6/e0APunTdxzA55c6oyiGGihqa5I3BHghJZNJ/2R0kpCpBNyk1tm40WEQMs+S9CjSA97Wr/dPTCdtB3otijDMQE/8J3M7qQZkNQ1HT48jGTQ2ct7cnBmjqK31qukaG0UgoElqktKFKiGZ0ovr30O2RDTIC812jfwe0kxj0ZaVr92+RcVVCCbBeX4YxY/Sr/2x9vh/S7+fDnOt8abAcwAuSL+/AMBzln5xAI8A+PBSZxTFMCxHbU3yCpOxOo1kMmkv5KMSeTmOX+4lnYFIu4GsoKbmV9J39qaMsvIztY++Aw0qViTvrdpL9N11Tw/nl166eI2rwl0mTZVs0rUtXJ+r0lB/v1fa6Okx2yik11O2hNrn+w91Lc+wFGqYMXUVl/695hl+jCJswB1r6ei+HEAfgK+mzy3LLGLDhWbOeTo6Bb8B0Oy5IWNVAP4BwF/lcJ+KQWtrZueXNMQmw35s6m/KxaRet3OnPYDt6aedvmpeHhPUILqBAeDFF0WeonvvFVGNe/c6eZruusuZ3+WXA+95j3MfzsWcrrzSPVc9D9KOHf4Rvf394t6Dg6LfddeJALnxcTEfGTB37bXAj3/svvb4cfEMnZ3AqlX2e6j3OnhQBPnV1QGHDgHd3e4+zzwj1iCREPc+eND9+WWXOVHZMijw+HHgt78VayAD9YaHg+cjEeb790MhIqjVfE8ywl3Fzp3h55cHMB7iZi0d3ZshCPa/zM5MfbKlo/ttAHbMzkwNWAdm7NsA1hk+2gVgP+e8Qel7knO+Wrt+O4Bazvk9jLEPA+jmnG+33GsrgK0A0NzcHH/kkUcCn2lubg4rV64M7FcuePVV4PBh8d+QqKoC2tqANWvyc4+orYkRL70kIpVbWpxzs7NAdTVwwQXma2ZngWPHgLVrxXXa8dzcHFb+9reCIJ0961xXWyv+0FVVwLnnOveU10usXSte1XOAk+BP719bK1JwVFcD558vIpjl5/oczz0X+N3vxPnXXxfNdE/ZT4fsJ9dHn4vab25OzAvAXCyGla++CnR0eJ+hrk78UPX71dWJduyY84w22NZGjiHX+sUXRUR7fT1w4YXONX7ft46A7z8sCvb/ydP8gnDVVVcd5Jx3Gz+0iRqFbAihegIwCeAIgBcAHAfwWwB/HzR2paqeOC++11PkEGCYnHg4ZV6/AK+XZDJpjwCWdR0At6eTVK2o6bdNKh+basjkFaTbH/RCSLq+Xs5L94aSNgo19bjqgaXPVX+O+XnHE0zea2hIuON2dorXIFXX/Lx33jYVnf5dqnUnwiRctHizLcIUkZ6F+qpg/58ixVMgDzaKd8ba4w/G2uPfirXHvytbmGuNNwU+Bbcx+56A/h/GErdRFAMVsSYWw+TEwyl/rzEfP/pkMmnOiqoSHZPnkmQAKtHfvt1uo/AjrrZa0eqrqXV1cb5rlzvdhDQiy2JG8hmC7CuyhGoiITx89LoZahbZtWvt48iIcP2Zm5vdUdlq/WzpBKATSNOcVXdkE3PX63LrjgKm30MIFPT/4/P7zBfywSgOxdrj22Lt8Z5YezwuW5hrjTcFGgF8B8I99tsA1qTPdwP4jKE/MYoQyFXiqJg1MRgmc/EaS37+8263UUl01NQS+j1VyeCKKxyXzq4utzvr+vVuqcRvF25yzw2TSkSmwVBrQaveV1u2uEuemu4DuIh48sABc6EhPadTpq2/352WQzWyb9lij/PQ1yQT1+M8uZtG/f+TD0ZxMEy/cmhLlVHkI86iItbEIlEwpIx0KdBrLJXyJgXUCYuJIOmE+uxZc+JAVVLQ1U1KbiXXrl7fhctr33rLO4bJM0nfYatSjareshH7gQG3h082DEH/scq1Ub2apFpLPw76vtVn1L8Xm+SUB3fTqP9/8sEohmPt8Y/H2uMXxNrja2QLc22x21JlFPmIs4j8mvjorB9aleAwMItQEoVqo9AJi6471wm5HrOgEy3OnR20iRHoaTr0z+vqnHvIMfzSaPjtsE3NIsUkk8nwkdKmOVxxhfuczEk1NGQvD2tyD9ZdSIPmo35vpu8iB0T9/+PHKMK6x94K4K8B/BDAwXSbCnktoQg4ciT4fMXXlrCVkEwk0P3eBtTWut0Wa2uBu+8OGHN4WHiZ7NnjPl9fL8aX95Q1JA4dcvc7ccI+9o4dwjuoq0t4VNXVAZs3u/u8/LL7WB2/q0t4OfX1CRdV6b6r13lQwbn7eGxMtAGLA+OhQ+Z6ErOzYv6qq29np/2+Kp58Ejh92n2uu1us6fCw+IHqbrEHD4rzEsPDTrEn1YVU/S4k1Poa4+Ni3robcZA7rP6ZX99KhI2DRLVVokQRxvYQJFFs2+YN2tNVU1FaE19YDH8er6eHA3aR6R1zcmQkeIdr0+/rEclr17p3vWGiqW16f2kjkLtwvzG6u83SQW9v+J24konWFZltMtzr95Ipxk1rqKuWgiQKUzCaKtWZpCZp61C9xDJN2WHzOkqfd6njIgjkWgq1paO7FsBOAK2zM1NbWzq63wHg/5idmfrfhWRiBLHr37rVcTk/fFgcA2IjKXH33e5+gLNjnpwEPv1p7ybozBlg1y73OBUBUwDU8DD6Tp1C3/OjTqW5wUHglw324Ky77hL9amvdpTbXrRPHO3e6y26+9prYgff3A9//vujz6qvis+ZmIR0cOyZ2t7K8aJgKcsePi6pxmzYB993nnO/uFpXlGAPe/W73NTU1wG23AV/9qpjHlKIAaG4G/vRPxb2ffhp417tEpTwburqA884T45mCCZ96SrwODIgd/mOPAcuXA+vXi/Vbu1ZUpRseFnP9ylfEGkxPu8ugXn+9eC9Lm3Z1CUlCHsfjjmQxOirGHh93yqWqlQF7e0Xj3L3GDQ0iePCyy9xSp/xM/+1wLsq7qiVZZYnWREJUOJSVCWX/wUExViZBf+UOGwdRW6w9/sVYe/y/xdrjP00f1+aSwqOQrdIkikxsDzbJwzYG4DbmFntNChYXou/oTDmATLtI9TpF/5584AH3okkvJd2PXd15mnb4cufd2yukD78dvN5Ud9ONG50dd3Oz246xaZOTvE8auP2S7m3c6M43pdeuUKvhKX2MuZ507y0ZJ6JLXqb1Ufts2eJIELLvunXCrVaVKkyZb2VMhJ5zS5ciMnE3tRm/td+Vy5ZVgFxMhQbyYMyeSr/+WDl3KMy1xW7lxCjyQQhtOZ4kswgzZtAYEsVkFAXLhmtTE8g4CJNKQl6nHks1kqnsp5qMT4dfPIJehjQTRiFbY6MYx5RmXM7/7NlweZgGBsRYMp5iYUEY1mU+pp4ep5iSPJ++Njky4m8IV9fStEY29ZCEDOKTBFnND7V7tznuRGUCuXo2mTYbOlNSf18oQJrxIiMfjOKHsfb4uUpywP9ANbP9kS9C6CcNhB3TNgZjpbNRFCQbro/XkzGxmsnfXursJSFvanIzCj1pnt8cbMxA251nxTAAr0dUT48j5ei1J/r7vcR10yZHarjzTsF8JDOQEowa/6FcmxwZ8XcN9mOkajyHvvYGAuy7Tn5ZY7P1bNI3GyabiR5XgzwXLioB8sEo/iDWHn8i1h5/JdYen0ynGr8qzLXFbuXCKPJFCE0MJ9MxTWMwJgzcKorJKAqWDTeMmsDELEyEKE00XYzCpnZSoUYpSyOwOu6dd/qrqHJp27c7tTEMz2JtQZ9rzCI5MuKsqyllh17rWv1+wjAKfR39mIT6vasG5mwkCtPmwlZuVaaYJ4nCxSwaY+3x/xhrj/9xrD3eFPa6YrdyYRS5EEJdZbVtW3g7Q5gxGxtFc6nEUin3mhT4h17Q+hr6TtK04zQxBkuKjEUCoOq9g9ZHqrpMDEqeN83DFnfR3+8fk6ESfNWLypR/avt2x4MqaBeit7QEshiEqEo1XV1uqUUn5Or3E6R6sqnv9DXRr9GvzSb62nRv9Vl05pF+dXnHRZBZ5EOi+E6Yc+XQyoVRZEsITbv/5cv9aUQmxNU0/t9VD/GZaxJu974CJB0LmkdebBS2naQpQZwtd5JsaWLqYhQ2acJkHDUFhJnUKdIeoCbe6+/nfOVKMQfVGCtTgpgIvLRLnHuu2OWbnkcScltKEL+mGNGTBw6I8aUhXLeJ1Nb614gIoxYyqXz0ZmPauSbSM2029Llpv7PkgQMFK1NaDGTNKGLt8Zp0FPahWHt8tRKVvSHWHv///K4tVSsXRpEtIQyySegtLHGVEoV3jBQfRcL5oWu7L2vG1Twg715PYWwUal9T/II0lioJ7lzeLHoyOc79iZL+mRx79263h87u3Q6R2b3bMTDPz4trZfT2HXeIfpdcYv5ByKjsjRu9Ki+VcaZS9s9NTWUqcvesEmvTWH4pT/zUQn4OATqT1dVV+u/B7zjM78g0P7WfyijUjVYEkQujSMTa48/H2uNvxtrjv0q/fz7NOLb7XVuqVi6MgvPsCKGfh5Lewo4ZbOdI8TEk3H/+RIiMq+WIMDtJXZrQU3VL426aoCeTSTeBV8dVvan8CKN6jcpwdHWWTiR1PXlnJ+ef+ET4H4mpSSYRRqLQ04Gka3S7fism9Zopr5VJytLtOeqO3GSjkIxcrl2+d+5h1VYGZrK40Yoo8qF66g/TrxxaOTEKFWGZRliJws8uod8rjGq7rTXl/vOn7BlXGxsLWxcjZ4TZSer+9rKpO9S0BOKSKGySSljDqWrM1XfIOjPTx9Qjs/Wob1vTr9u+3SHAa9dmroLq7PT3BDPVmZBSUyIh4iT0dZNM2KSa0+1Kqo3H7zvOFmEisQ2/h0UDf0SZRb6M2e+Jtcc/FGuP/xfZwl5bzFaOjMLmdQR4Ce3EBOcrVoQg7G3h7xXUas9NCRuFJlHYMq56ri93KcMGuXtXH8bwJ08mk/7eVHKsgHEW+9lsI7pxVlfn6NfZYiVMWWcBYbuoq3OON24UTOPOO+1f7rnnuo/Tu47kAw94XYEXFgSx1912FQZjXDcb41QZiuyrMpps7Q9hELTZMDCT5IEDkbRNSORDong4HUuxL9Yevzfd9oa5ttitHBlFJrEQExPCeJ0tYc7UxtHWKpgEh9dGYcu4mgnjKiUmJsTz6d5diwipi178rejR1HJHLAsB2ZiIChOjAETUsazBwLlgEjrHN+38ZRR2UNP7XXihwwRsEoVP0N7ib0VVwdmeTWcCuq1Iv0ZlKGo+K87DR9kXA7bfSUSRD0YxE2uPszB9S93KjVFMTIT7H0tCayP0y5aZVT26miksg3Axm/TuyGWMSyT4oRuHQksnOcc/5BkTE8KbaxSJRWYnJafFim5hCM7QkFOkx5SoTiXCsu6EJLB6LIF6D504q2k39MjqjRvtxLyx0S5CZqJS0pmCVFeZGFFvr/v/ozNfvxKnuleQLSFhZ6d/IF02MRIFBjGK9viXY+3xC8L0LXUrNqMw2R7sHkbBhNbPmG26d1hCHmhXSKWMf/6w9o5ykyjaWh1vLsks5PEiUQmji5Z5jWSEsk5Qq6vdBFV+Lo91903pzWQijrqap6kpnIFJJewqoc3Eq0k2afdQCwgZVGWL6jgVqm3HNr5qz7jjDvs9gphAWFVfEUGMoj2ejLXHT8ba49+MtccflS3MtcVuxWQUtpiHMDYGG6ENm27Dr6/eli8PZ0MIsyYFi38w3CcXg7lguApzSLcxJLxumCpUtUja4L0YXGZqmzbZK8GtX+9mFHqaa5vKRbagOtpqu/RS77yCxrc16VlkY2q9vaJmtonJmjyVdKlELwerB+rpzcQkSKLIO/LBKLaYWphri92KySgylRpsTbdR2KSKxkb3/cO60lZVhSO4YdekYFlflfFzZUbOd+Peeba1aIZRVTWkJgZUdOee7LE6MbcROSkN6C6uvb1mAmwSDzP1SNKb9DYyjaNLMDrhVdVCmudRct8+93nVqC3nrTIDtckUJqbn6+z0GsNtaqdS2yg0LHlGEaVWTEaRScyDrS1b5iWAfv3VvtkwKj+CWy4/9Hyk95iYEDYJXaI40drldcvU02lIF1lTkR6dCAP+mVp1QijzA+lZZOWu22QTCMsspDFczqe21gnYk/eTzMhvzjJDLedW9dyiRKET9N27HUaYSrnno67B5s1mJiLzRunusprdqOBeT1mgXP4/2SKXgLsfpF9Px9rjv1Xa6Vh7/Ld+15aqRU2iMBmB/caVUsXERHj1tYk5maSBcvmh5yVhYMrx5hpDgre1LAgmoRMslQhZjKpWRvGJTzhEUCeGNkIsVVsyVbYtWaFs0gYyMGBOLa5+qfr977jDWQ8pLalMyq/phFhb20UbhXqNJonx/n43M1CPbeuzbp2zLvLeJiZgs4+UEOXy/8kWJFEYEPSlhlGvZBOzYPp/X321UA/Jc2FsHCZiWleXuX1ElTDK5YeeN4O5KV20TrR1Im3Sx6uMQibdk8btCy8U53Q7RW2tWSUliWB/v7hmyxYvwZW7cXm9GqOg2yJsTUoEKlTCr/Y1qX+km64FyWTSbicw2RDU1tXF+a5dduZqShAYAZTL/ydbEKMwwO9LzURHbtvZS0Kub/QK2SRDyziWoi14TYoFW8BhWIO8B0EulaYaFdrNkwcOuPX8qhH2jjuc852dwrU1k5TeplrSqp1EtaOkUsH1tdUxTInsbERceknJ529u9rr2Ku8XDfx+aUv8mJiNkdjSk0cA5fD/yQXEKAzw+1Iz1ZGH6Z8vw3dQyzSeQl4TtCbFgl/akKzhZwA16cmlATgtNSxmBZUeS6ZqeWptgjvucH/21lvm3YTKJExpKlSvLF01Zot+1hmZqurq6nIYjTSmq5HaeilTybBMUcgPPOBNdyJVREESRSJhNnRHmElwXh7/n1xAjMIAvy81Ux15mP75MHxnSvzD9q2rEwR6ZCQZ6MWUjcfTtm2OZLVsmbdgUi5rHxomNZQtR5FKMLu63IZbNbmdOsHt2zMvc6qW+zS5mUpIhrFli9jp2zLHSuYDOGocvWKftAGoyQhNTEeXarR1So6MOClH1Dmr/XXPLvVYX/sy8VzKBZXMKKpB8KC1FTh82HweACYngV27gCNHxLk1a4ATJ/z7V1UBCwuFm7MOzgHGxGsQXn9dNEA899at4n1fn7vf5KT47MyZ4L4SH/848MADzvHCgnO8b5+3f9DaB0I+uHwPiOPhYSCVchalqgq4/npgyxZgzx5x/skngR07gNWrRZ+uLmB6GnjpJWB8XBzX14sxd+503/e++wAAv0MNzp2exmfx5zjnvVeg79sfsc81HgempsRc5JwBcY/XXhNzuOsu4ORJ8f6NN4CXX/b/Ic3MAD09wOysOH76aWDZMvG+qQn4zW+Ae+8Vx4kEMDoqxpZ9JMbGnDmNjorX8XHRAOCDH3Q+HxwU5xMJcdzQ4Ix9113AwIA4v3o1MDQkrpuedvow5tyjocG9FoTygI2DRLUV2kYRNsjOr38xm1rJLqjvyEhy8b1JzZaN26rNRrNsWeZrHwh1d65mh1XVIXpCOT2lhMEY6zFmq0WEDA/3Omo48Ba/b5nBmK3bJJqaHMOzVC+pAXnqjlz3ItLHzVRs1b2UTBKFhGZz8AQh6pKA/t70WRl6LuWCSpYo8kagy6UV2uspbOrtoPKlxWoqkQ2aj8ooTKoePzpkU0P53S/TtfdFvlUe8/OLjGCRUajqnIEBb04mpf0Ine5z0s1Vej1t3+5wRH0uthQfmTY9JkM/HhhwMy1VfSaPpZpNszl4GIWe6C/iRD8bEKOIUCtkHIVfgj+VsGYqRaiusYVqknnZ0p3rjEJKCSrRDvLgMu38M5UockIYI2qY2hF+EoU0EAfFP+gEeX5eEGXVg8nPoOvnNZRLk/OXc+/tFQbuCy90BwNKF+DWVnc+poUFc2yJTOInJZSenpIHwBUblcwoqkqs+YoMpH7eBlWHvmuXo8cPg1Qq+3mFxeHDwP79wK23Am1tQg3c1gZ87GNAba27b20tcPfdzjMfPiyoQZCN5cwZ8ewqbGvmt5ZZQ9V1mzA6KuwBeh+pJ1dRXy9sEjquv16MUVUFrFoF1NS4Pj6GJu81Y2PCBrB6tWN7AMT76Wl33+lp4NQpR99vwrp1wPbt5vn5oaYGuO46Zw0SCeDaa4Ef/hBYu1bcu7tb2GzeekvYM86cEeebm8UYO3YAhw6J983Nwh4CiHPvfrf4fO9e4JlngK9/3XlWQrRh4yBRbfmUKDLZTV99tdO30NJBrpKF7Tml19O2j+nV7cLVpADMKqtMvJ4C4afXzodEoVe+03fPcuesehLV1vIJ/CmfhiUYTu7EdTWXKSaipobz7m7nWJU4Nm1y7+79vJ90MVXmdbJFXKvPo97bFMnd0+Pkeurvt8eN6HaOCkclSxShiG+UWj5tFKU0Qheq+bmZJpNJfujGIX5fdUJhDiJf0hCGQo1f0HTjJhdX1XdfdflUiZuaMlt91XMJqcS8p2cx2nrRFVQSROlyumWLQ0wBPoO3L97zoZX9fOYazU6SibpKzvGOOxxbQm+vUFcNDDg5kTJpMiusDabIdc6NajBX2U9TWvElxiQ4r2xGQe6xFmSqPionLFtmVxPpbqaqq+/4OLD866fwiflxnAUwiFGMYhA7MI4xJABwAHbXRamyKgg4FyoZ6Z5ZXw88+qjjZsm5cAXt7RWqHumWyblQg0xPC1XNeec5bq/SNZZz4ZapqqXkfeSDjY0JN9BDh4CjR8X7ZFLoDdOusu34pejf2YmP/GhMqLN2QMxr9WpnfHXspibg+HHzM0u11NQU8Pu/L8Z5803gj/9YjAUAdXXAxReLL/Dll+3r19go1uyuu8Tz6qq2VEq466qQ7ru33WYeU67V4KD3M87tcyFEDzYOEtWWL4mi3FVIYZp0tFGlCVXto0tNwpjtzbiqVolTW2AxpHzDpFrSjbPqTlZ635iuUwPnpAuteo2+e5bHerCa7l2lRlpL464uAYX9Am2J86SxGBCeSfPz/gkD1Qp8emlROS89mltP3qc966KU5eedpdcAr3BUskSRERHOVwOwBsA/A/hF+nW1pV8rgG8BmAHwcwAbgsbOF6MoB9fWQjQ/d1nH68lNKG02ipxsDdlCI+Jt+BVnWOBteJ5PXLPfTph09YlM06G6y+qFhUyMIpXiEw+n+EOrEt7xVKZkitdQ77V7t7ngUW2tSMEtkw76NUmoZYEhv741Ne7a3rqnl1SjSXWTnG9bm5tJpN8v1uhQVHSL6jW17gYxisigHBnFPQBuT7+/HcAnLf0eB/C+9PuVAGqDxiYbRXCTeZN0qSmcROEwjXzYI/Skio2NPpKJQTJw1cSuTYlrdeIUtJOXBFKXDtJET2UUE9fs57W1Ka4z04mHFSnGJOGouaV0A3FPj9uwHbb+hEq8ZdryMNfZ0mSYkgjKZ1LtQ6mU+P9IyUQyKpUpqlLaEgExijw3AM8BuCD9/gIAzxn6XAzgB5mOnW+vp2xrPpR7M2WZHRlJLjKJMST4n+DL/AL8mjMs8NU4wYEFj2E7F3VTRpliteC4tpYFT01sgPO2+pPBOZ38dt8ymE4h9sl9+xYN3214npuY6UOrEo5x3BbxLKUW+Tya5LIoIdgqw/nNN4xUIVu2u3zlumQy6Z8KfAlJEhKVzCiY+Ly4YIyd4pw3pN8zACflsdLn/QD+AsBbAC4C8G0IKcRjpmWMbQWwFQCam5vjjzzySOAc5ubmsHLlysB+zz4rXMorDStWCNvmK68452KxOfBfn0bDqnkcO6cFx1/h4IrxmoFjA17APKoxixYAwqba1ibyXUm8+irw61+7123FCmD9enc/v7VdsQK49FLt5EsvAfPzQEsLDh4Up1owiwVU40VcsNgtjoMiLqClReQ8OnZMGKQ7OkQHec4E1aD74ovAwgLmVq9e/K0cPCjuuRbHcAxrMYuWxWPU1goPCP3eprEl5IOY7v3SS+Y5qqiuFmui3vv0aeB3v/P2kZDzywFh/z9LCVFfk6uuuuog57zb+KGNg+TaIAj7Tw3tBgCntL4nDdd/AMBrAN4GoBrAPwH4aNB98x2ZXQlGbVvTVWsjI0lhd0jpcRROE5KF22ahqqD8VHZ65Lbf2lrdeNM71bb6k+m+2lykRGHayetpMkyxA4ZaEOpvpa01xYcw5FHHLUoUfrt63dDuV/jHZJxes8Y+rry3mqpk+3bH1tHUxPkVV3htMlmWEI367rkQiPqaIKKqp8sAPKEc3wLg/qCx880oKtWobQogHBlJLtbwthNxr2FbJepB66V6SvmlLgmyf4ia2Auua2rPXXBsFOoHihpk4k++wttWneCMpXjbqhN8Aje5E/1JwqvUhVj8rQwNuWwUi/dd/qawUeh2DsDJl6TW49aD7zZvdnsXffzj7uuDbA8qc5O2BMkYpcH+zjvddhJbPeqQiDpRLASiviblyCg+Bbcx+x5Dn2UADgE4P338OQCfCBo734xi27bKlip0RgGInb/NNhMkUeRrrQJtH0NDfOaaBG9rTQn33NZ0jWxTUaE0ITTZRGqq3uQTDy+YiXz6ukV9fHrciWv287b6k463VevtwkBt8mJqanKC5CSjUAn6/LwrwptfeKEjkjU1ibrcvb0iwE4tMqQ23bvIZMyX54PyXIVE1IliIRD1NSlHRtEI4DsQ7rHfBrAmfb4bwGeUfu8D8BMAzwL4RwArgsbOtzG7Ej2ftm0zMwI1KWDjmhSvrX7T9fkKvMkncJMxrqKtNaUZyMOn/TA1/XtweUatSQlXWJXQ6RXrJHO4Zj9vw/OcIcWrqsxzuuDckw7RVj9IRzEv/lZMhNYU6yDLiuqf2WpBm1RgNTVuyUKOpZdjlcdhCb6PtJUJok4UC4Gor0nZMYpCtnwyikpUO0nX2CBGwZimpmkTOaDGq7zpPKTOvvbclMhQW7PA+7CfL8ebWc2RMUeisHtGKcxCNhmfoEgQQk0UdM808dQJe9pt1vVb0QmtiUnYPvMjyqY0GOo85OumTW71lXzeMHYGkigKiqivCTEKA8J8qZWqcrIxQJdEIWtUK0REXKcT3pTLTXX0vN38RKsgbDdjP1+2LMUZUryt/mRGrsZSneXHrNtaLbtjafD2udbDKExMAhBlPw8c8C/yo7awxmwVJonCdK20Vag2Ce07skJzL/atxRECUSeKhUDU14QYhQFLVaLwayqjqKry2gn8DNx6XIEntUYiwScmUqFVedJA7usZpQW96YQ4LJNoxDHvBwsLi4n4kiMj3nQd27fbmYtpHXQbhYSePsMvFUeWRH0Rtvrc5PWUF0R9TfwYBSUF9MHddwM331zqWZQGqZS3HratnjXAMIhR7ICS7G562qnDnEhgsnsUu3YxnDkjYi+CanDI5IX2ewKtSH8gazLv3evUpGAsnRyRw53IkC++a8NhXIkk3odvegcfHBRjXXONiDv4q79yPuvvF58dPy6S+m3bJmpL7N0rPpc1GmQywsFBQeZNqKoSNbGbmkTiv3TtbWtmR1PtjLAYHhbzkNcra0Ug+MLGQaLa8u31VOpdfqkkCtnCxUgYJAqlTTxsliSktKBLDWq8hdVGgd8J11bAHfeg7I5N8Q4yspxhgT+0/C+9A+s1rQcGxG9F7aN7LXHuRFr39Djz0d1aTaonVQUkr1cN1xs3Bo9RAkR991wIRH1NQKonL4hReJuJUeglXlU7Q12d8EByp9JY4D9Cl2uQh1YluM0LqrbWqS9uy0Lrvm+KN55z2mESgDtQTSLlJO6TzELO86FVA+HyIqWNxp760Kb7pe/p8WrSGYz6mfpet22oDEum9pCxHrmon/KEqBPFQiDqa+LHKKgUKsEXa9YAGzYI7cQttwAnTjifcQ6M72VAfQPGkMAg9mAUO/EuTOPH6MLYebuBRAIfOT2OUQwCitonPQLOnAG+9jXghReA1ALHCy84qi5w0b+vT2h5+EIKPDGI42+uQl9irdBfJRKivoNeE4ExnLNvFPdXJ7AD4+Cowg6M4/7qBM7ZNybqQ6xb576ms9N9/MMfiloTx46J+/jdL33PRTUO594+O3Y4rGDHDqEKAkSNCB2bNwM/+Ylzv7Ex4MknxXFDA6mLCMWFjYNEteU7jiKoBGolNV2iWL7crPZRm1P+VUgMjrpnQUgj6Z29t0JeajF4T/ZzqY5shlc9fXeAQXbiYfeufuLhlFvdI1U5Jm8lmcJDej2FuJ+rjxxfzQw7MOAYrKWbq81TSqYZ0ccuA0R991wIRH1NQMbszDE5KYy5tkpxlY62NmBuzi1BmHDkiDQ4ix3uXRgG0pXwWluxuLP/1F8ywFUxkOEk1mA53sJ5q5eL3ff4uLNzV6vZjY66P9+zJ5xBlnP0Tbl39X1Tg5jEKF75xwYwJDD6P0dx9yZACjHo7RU7d/V+LS1ifM7DGYAZE7t+OdfBQWHYBhyDt7wX58ATT/gvsj42gVBs2DhIVBsVLsq+jYwkeV2dKiUEN2lT0I3VegLAiQl7bqc2PM8Xd/D6zl3f4fvtqG16fy1uwKkJnlqc66Ebh9yGYpkjSSYFlOPJ+tz6/fzmY5IadPdhPVBPJvrL0n210Ij67rkQiPqagCSKzHHkSKlnUBqcPWt3R9Uha2RLm4Ksvd3a6tTO3rDBOWdziT2CtC+sulOXO3e1vrTfTn54WEghsg/nwD/9E9DcLHb1ALBnD3627wn83tlpqC6zZ84A1/9oGC/8ExcnOBfurtPTwDnnAG9/O3D55aJm9cCAsC80NIg+DQ2OrUEHY+KzkyfFmCpU92HpbnvokLvPqVNCApE1wUmaIJQIxCgMmJwU7u1LUe2USe2NBx90mERfn2KEhqO6O5NWN/kxn1akufLgoEPoUylhSFYhPwfcRJNzt6qqvh549FFRFAMQhJ0x4Omn8XtnpzGGBLBoWBfjHDkCQdRfe03cY3RUjLt3L/DBDwomAQg10aFDQFeXIPYqEdeJOeeCSajqJhO+/30xlhoPIq8ZGKBYB0LJQYxCw1K3TYRFW5ubMejYtcthEn6orX4Ld183BTzf5RD6f/gHoLtbEM/eXtEA8bncma9e7ezkpfQh+0h0dQFXXAHce+/iqc+uHMDg3CiGcBcacAqDGAXA0BpLCeYyPS06yvF0yF3/9LQYX9pLOBeMTJUw5Ly+9CXgN7+xL4IcSzIElbGMjRGTIJQc5B6rISyBKydIDUYxIVVLNgSr7jga2at48HPV6Gv9gUMs6+uB225zjnt63Lvrp58Wx6dOudU5KrOQmJ52MQkAOOeBMdSeCzTgFHZAuO3WnsvxjYt3OvccHxciZZAkMD0tpB7JJMbHvfOqqnJC3P1wxRXiVXep9YvqJhCKBZvxIqotV2N2pSYCDGvMDtNvMWGgD8I4AzB4DdcTuGkxLbhIXR7SqG0yfhvaQ6sSfNvHxNhjejS5LPijGZU9AXeqQTqbeZmq6pkKCeWQtK/QiLrhthCI+pqAIrO9sH2pS9HbKRNGsWJFiKJCPFwtD1cVu4UFPoGbeC3m0p87HkkTEz4Rzpx7iaohG+soBvgohOfRfdUJJ55CHVf1QpKts1MkBZReSbI4kSkBYNC8bPEa0tsqj0n7Co2oE8VCIOpr4scoSPWkIUilspTQ2CiaevzZz/rbJiT6+oSxu61NHOtqdukxBQAYGgLicezC3TiDOgAcoxjEEIZx5gywa9tJ98WDg24XKsaEyiqRwGR8Dz7bINRIx6rWYaqqB2MYwA4INdIYBvDKfAN27YJXzROPu2M5BgaETaK2Frj+enH84ovi8+uuE2oqfV6cu+cl4yl0tVhvrxPpvXevuHZoyOz5ZfOqIhCKBRsHiWrLVaKYmCjuLr6cmi3Xky3/kl9+JtO6Gvsru/8xDHC9vgWQ4gwL5kp2WonPQ+/fzWtr3dHhMl5CJgOUx4tqpxDjJicnnWM550zUROrx0JA7XqOMpQY/RH33XAhEfU1AqicvSPXkbX6qJz2ja1CAXUaQwW3KgGrW17ZVJ8xlQzUi7U4+6C2wpB6P1g+Z1Tzp8qeLSKXMv5Vc1ER+jCQiiDpRLASivibEKAwgY7a3BdkogqrOuWwOChxpIuWWJlQCqRmRPTYKFSZbQiLBWcg63YtMLSTBthKACiD42SLqRLEQiPqa+DEKslFoWLOm1DMoX0iXV5vrq+m8jEs5fBjgnOHwYXE8OcmFXl4W09GC68YwiLZWng7q0wwcVVVenf/oKFrbzPEGjY3CVsKYeF0MFNQNJ5nGK+R6PYEQERCjUDA5CZw+XepZlC8kE5XV53RwLlJ2TE4650xxKYsG6vFxEbm8Y4fbiJxIIIFxvHDjIPo+xM03MsQb3P13HLW17tO1tWLoF14QQ7vSmBMIhFAgRqFg167MUlgsRUxOiqyyNjgSgzi2Sh+nGwRjGBsTUdbSM0h6+tjqLkgmoTEWjI+jb2oQD/4PbpYeCARC1qAUHgqWaiLAsDhxwp2/yYYzZwTT7esTUogpVXkrjjiMIZNazrrLqRqR3dCAvpsZ+pZonXMCoVAgRpHGUk4EmAnCpjc5csSuyluON3A3/jswuNYh9pno+zNhLAQCIWcQowAlAiwEWlvtqrxzVp6Dvo+udRcmIkMygVC2IBsFopkIsBTIJPng299uV+XNzTFMdvvYIQgEQlmBJAqQbSIstm4F9u8Px1S/+127fQIAdt3B0Pc8qYsIhCiAJArY3T0JbuzbB9x6azjazg1erSqOHAExCQIhIiBGAZGcTve/J7gh1U5f+1owE5B49VV3UkEVxJwJhOiAGAWEG2fYnfJSRU2N8AoLW08bsEe5uzLHEgiEsgcxCgivp898JvxOeSni9dczW5/qamGfOHHCfVFjozcIbnJSRHRXVXkjuwkEQulBjALC6+ns2VLPIrqorQW2bQPa6k+BgaOxkWN+HgA4VuMkAIdZnDoF3HKLwxDcuaC8kd0EAqH0IEYB8nrKBcuWCS+or32V4+7LHkUKVbjnrUEAHMtxFiexBoCj01tYcDOERMKSC2pXUR+DQCD4oCSMgjG2hjH2z4yxX6RfV1v63cMY+xljbIYxtpexwlgRKGNs5mhsFJKEDFI8fIRh6/dvweQ1+/GR0+Now2GcxQrfMc6csbvPEvMmEMoHpZIobgfwHc75OwB8J33sAmPsPQB+H8BGAJcA2ARgSzEnWanIld1KDzGvJMBw8zdvwQY8j8PIza2JvKIIhPJBqRjFDQD2p9/vB/B+Qx8OoAbACgDnAFgO4OVCTObVVwsxavniYx/zugPX1gLnnw+sXBl8vZ8kADAcxgaE5UVSMtHnQl5RBEL5gPESuPowxk5xzhvS7xmAk/JY6zcC4C8glNz3cc6NmmvG2FYAWwGgubk5/sgjjwTOYW5uDivTVPHZZ5dOevHqaqClBZidRdrgLM6tXg3U1MxhdnYlqqudzwqJqiqRChwAfv1r8R2sWAGsX19e6kD1t0IQoDXxIuprctVVVx3knHcbP7SVvsu1Afg2gJ8a2g0ATml9TxqufzuArwJYmW5PArgi6L7ZlEI11YAut1ZVlZ9xtm3zPuvy5ZyvWOEuhZqfkrAp3rbqBAdSfNkycU6+ukqiljmiXuKyEKA18SLqa4JSlELlnL+Xc36Jof0vAC8zxi4AgPTrMcMQNwJ4inM+xzmfA/B1AJcXYq59fcK3X+5uyxGpVO5jbNsmIqt128LZs16JivPcbRltbQx3P7AatbVs0ei9sOColqigEIEQDZTKRvEogFvT728F8L8MfY4A2MIYq2aMLYcwZM8UakJ9faJMJufA1VcX6i7FQ12du070xITI1ZSJNxHnzhiZZI4FHGawaxcj91cCIeIoFaP4ewDvY4z9AsB708dgjHUzxj6T7vMVAP8O4FkAhwAc4pw/VozJffvbgrCWs4QRhDNnzHWiM/Emamtzxti/P7N8WDL62loKldxfCYTIoCSMgnN+gnN+Nef8HWkV1avp81Oc879Iv1/gnP8l57yDc34x53xnMecoJYyoMgsbQwibAFH3PJLqOVuSPxXbtgUzJnJ/JRCiA4rMDkAUM8vqRF7NpbRrl0iAGMQA9XxMgDg+ftyRthgTKq6q9K9o2TLBJPbtc64xrR+5vxII0QIxigCohm6p79+2zUv8qspoJW+9VTCEqiqgqQn48z9351Lav18QahuzaGvzNzRLaSuVAubmnLQc8/NuJiH76utnYkIEAqF8UUbkrXyhEsYXXhDEUCd+Bw44TqFh1DO5oLHRfo+6OuDTn3YYw4kT3oSHZ86IHEtzc97rC7Hb19ePmASBEC0Qo8gSfsRvfLyw95ZR0cuXu88vXx4+HbhIAe4+V11Nu30CgeAFMQo/6BQ3DAWGILSFlipOnBDSTGOjI9Wcd15uY1ZVEZMgEAheEKOwYXgYGBx0mAPn4nh4ONTl4+PZG8HDxiy89ZbIzSSlmlxzVmWSxoSKDREISwfEKEzgXFTYGR93mMXgoDg+dSqUZGEy4k5MiEsnJuzXNTZmFrOgxiPk6nK6wj8r+CKo2BCBsLRAjMIExoDRUWHxHR8X2+bxcXE8Oho6t4XNjtHXJzyndCxfLm6jpxTxkzBU5pCJK6/+CLW1IhlfGOzaRcWGCISlBGIUNkhmoSIDJhGEffvc8QhtbcDnPudmJjKlyPy86KszgeXLheeSVP8AXinGBjU9h3RZDZuxlaKtCYSlBWIUNkh1kwrVZpEHZOI2qquypBH7xAm3+gdwj+kXK5GtyypFWxMISwvEKExQbRKJhKCmUg2VZ2aRCVTGsnKl1/hsUv8UIjKaoq0JhKWF6lJPoCzBGNDQ4LZJSDVUQ0Pe1E+5IKz6R0oKu3aJz1pbc0/xXYgxCQRC+YIYhQ3Dw+6iDJJZlAGTAARxPnzYfF5HX1/+iXghxiQQCOUJUj35QWcKZcIkAFL/EAiE4oEYRURByfYIBEKxQKqnCIPUPwQCoRggiYJAIBAIviBGQSAQCARfEKMgEAgEgi+IURAIBALBF8QoCAQCgeALxkuUjqJQYIy9AsAQiuZBE4DjBZ5O1EBrYgatixe0Jl5EfU3aOOfnmz6oOEYRFoyxKc55d6nnUU6gNTGD1sULWhMvKnlNSPVEIBAIBF8QoyAQCASCL5Yyo3iw1BMoQ9CamEHr4gWtiRcVuyZL1kZBIBAIhHBYyhIFgUAgEEKAGAWBQCAQfFHxjIIxdi1j7DnG2C8ZY7cbPj+HMfbF9OdPM8Y2lGCaRUWINdnJGPs5Y+wnjLHvMMYslbcrB0FrovT7T4wxzhirSDdIHWHWhTH2n9O/l58xxj5f7DkWGyH+P62MsSRj7Mfp/9AflWKeeQXnvGIbgGUA/h3A2wCsAHAIwMVan48D+HT6/Z8B+GKp510Ga3IVgNr0+220Jov9VgH4HoCnAHSXet7lsC4A3gHgxwBWp4/XlnreZbAmDwLYln5/MYAXSj3vXFulSxQ9AH7JOf8V5/wtAI8AuEHrcwOA/en3XwFwNWNlVMou/whcE855knN+Jn34FIBYkedYbIT5nQDA3wL4JIA3ijm5EiLMuvxXAPdzzk8CAOf8WJHnWGyEWRMO4Lz0+3oALxZxfgVBpTOK9QBmleOj6XPGPpzzeQCvAWgsyuxKgzBrouKjAL5e0BmVHoFrwhh7N4AWzvlXizmxEiPMb+WdAN7JGPsXxthTjLFriza70iDMmgwDuJkxdhTA1wD0F2dqhQNVuCNYwRi7GUA3gC2lnkspwRirArAHwIdLPJVyRDWE+ulKCMnze4yxSznnp0o5qRLjJgD/yDn/B8bY5QAeZoxdwjlPlXpi2aLSJYpfA2hRjmPpc8Y+jLFqCFHxRFFmVxqEWRMwxt4LYBeA6znnbxZpbqVC0JqsAnAJgMcZYy8AuAzAo0vAoB3mt3IUwKOc87Oc8+cB/BsE46hUhFmTjwL4EgBwzp8EUAORMDCyqHRG8a8A3sEYu4gxtgLCWP2o1udRALem338AwHd52gpVoQhcE8bYuwD8DwgmUek6ZyBgTTjnr3HOmzjnGzjnGyDsNtdzzqdKM92iIcz/539CSBNgjDVBqKJ+VcQ5Fhth1uQIgKsBgDHWAcEoXinqLPOMimYUaZvDdgDfBDAD4Euc858xxv6GMXZ9uttDABoZY78EsBOA1TWyEhByTT4FYCWALzPGphlj+h+hohByTZYcQq7LNwGcYIz9HEASwF9zzitWIg+5JrcB+K+MsUMAvgDgw1HffFIKDwKBQCD4oqIlCgKBQCDkDmIUBAKBQPAFMQoCgUAg+IIYBYFAIBB8QYyCQCAQCL4gRkEglClaOrrf39LRfXGp50EgEKMgEMoX74fIPupBS0c3pd8hFA0UR0EgpNHS0V0HkXohBpFO+m8B3DQ7M/X+9OfvA/Dx2ZmpG1s6uucAPADgjwC8BOC/A7gHQCuAHbMzU4+2dHR/GILY10GktRiBSE19C4A3AfzR7MzUqy0d3f8BwP0AzgdwBiIj6xoA/xsiSeVrAP4TRHDoNID/E8BjELmn3jk7M3W2paP7PIiU1++cnZk6W5AFIixZkERBIDi4FsCLszNTnbMzU5cA+AaA9paO7vPTn/85gM+m39cB+O7szNTvATgN4O8AvA/AjQD+RhnzEgB/AmATgLsBnJmdmXoXgCcB/Jd0nwcB9M/OTMUB/BWAfbMzUz+ESA3x17MzU12zM1P/nu67YnZmqnt2ZuouAI8D+I/p838G4P8lJkEoBIhREAgOngXwvpaO7k+2dHRfMTsz9RqAhwHc3NLR3QDgcjgp19+CYCTyuifSRPpZABuUMZOzM1OnZ2emXoGQDB5TrtnQ0tG9EsB7AHy5paN7GiLH1gU+c/yi8v4zEMwL6dfPZfa4BEI4kJ6TQEhjdmbq31o6ut8NoU76u5aO7u9AEOPHIIoVfXl2Zmo+3f3s7MyU1NumIFRJmJ2ZSmn2AzXzbko5TkH8/6oAnJqdmeoKOc3Xlfn+S0tH94aWju4rASybnZn6acgxCISMQBIFgZBGS0f3hRCqoQmIxIjvnp2ZehGiQtkdKMCOfXZm6rcAnm/p6P5geg6spaO7M/3xaYgU5344AODzhZgbgSBBjIJAcHApgGfSKqAhCLsDAEwCmJ2dmZop0H37AHy0paP7EICfwSmt+QiAv27p6P5x2uBtwiSA1RBZSgmEgoC8ngiEALR0dN8H4MezM1MPlXouOlo6uj8A4IbZmalbSj0XQuWCbBQEgg9aOroPQtgFbiv1XHS0dHTfC+APIWwqBELBQBIFgUAgEHxBNgoCgUAg+IIYBYFAIBB8QYyCQCAQCL4gRkEgEAgEXxCjIBAIBIIv/n9z6xTrXhI+qQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "\n",
    "#importing training sets\n",
    "\n",
    "trainFile = open(\"./Digits/ZipDigits.train\")\n",
    "train = trainFile.read()\n",
    "\n",
    "#preprocessing: splitting by rows (individual digits' data)\n",
    "train_rows_raw = train.split('\\n')\n",
    "train_rows_raw.pop(len(train_rows_raw)-1)\n",
    "train_rows = []\n",
    "\n",
    "#preprocessing: splitting data within each digits' set and saving only data for '1' and '5', labeled as 1 and -1 \n",
    "#respectively\n",
    "for j in range(0, len(train_rows_raw)):\n",
    "    if train_rows_raw[j][0][0] == '5' or train_rows_raw[j][0][0] == '1':\n",
    "        split = train_rows_raw[j].split(' ')\n",
    "        if train_rows_raw[j][0][0] == '5':\n",
    "            split[0] = -1.0\n",
    "        else:\n",
    "            split[0] = 1.0\n",
    "        train_rows.append(split[0:257])\n",
    "        \n",
    "#extracting symmetry and intensity features for training set\n",
    "for z in range(0,len(train_rows)):\n",
    "    tot_sym = 0\n",
    "    tot_int = 0\n",
    "    #matrices used to store left and right halves of each digit\n",
    "    left_train = [[0] * 8 for _ in range(16)]\n",
    "    right_train = [[0] * 8 for _ in range(16)]\n",
    "    #loop over rows of each digit\n",
    "    for x in range(0,16):\n",
    "        #loop through each pixel on each row and store in left and right halves, sum up vals for intensity\n",
    "        for y in range(0,16):\n",
    "            tot_int += float(train_rows[z][16*x+y+1])\n",
    "            if y < 8:\n",
    "                left_train[x][y] = float(train_rows[z][16*x+y+1])\n",
    "            else:\n",
    "                right_train[x][y-8] = float(train_rows[z][16*x+y+1])\n",
    "        #compare left and right halves for each pixel in a row, keep total absolute values of differences\n",
    "        for i in range(0,8):\n",
    "            tot_sym += abs(left_train[x][i] - right_train[x][7-i])\n",
    "    #getting the final symmetry value for each image\n",
    "    sym = tot_sym/128\n",
    "    #getting the final intensity value for each image\n",
    "    intens = tot_int/256\n",
    "    #appending extracted values to data\n",
    "    train_rows[z].append(sym)\n",
    "    train_rows[z].append(intens)\n",
    "\n",
    "    \n",
    "#format data in list of [sym, intensity, class] for each training example to pass into gradient descent\n",
    "nnD = []\n",
    "for t in range(0,len(train_rows)):\n",
    "    samp = []\n",
    "    samp.append(train_rows[t][257])\n",
    "    samp.append(train_rows[t][258])\n",
    "    samp.append(train_rows[t][0])\n",
    "    nnD.append(samp)    \n",
    "    \n",
    "#rest of code is plotting points\n",
    "#plotting symmetry (x-axis) by intensity (y-axis) in scatter.  Marking differently based on whether a '1' or '5'\n",
    "for r in range(0, len(train_rows)):\n",
    "    if train_rows[r][0] == 1:\n",
    "        one = pyplot.scatter(train_rows[r][257], train_rows[r][258], marker = 'o', color = 'blue', label = '1')\n",
    "    else:\n",
    "        five = pyplot.scatter(train_rows[r][257], train_rows[r][258], marker = 'x', color = 'red', label = '5')\n",
    "\n",
    "pyplot.xlabel('symmetry', color='#1C2833')\n",
    "pyplot.ylabel('intensity', color='#1C2833')\n",
    "pyplot.legend((one, five),\n",
    "          ('1', '5'),\n",
    "          loc = 'best')\n",
    "pyplot.grid()\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network forward propagation and back propagation for \n",
    "#                                   2-layers with hidden layer containing m neurons)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "#forward propagation algorithm \n",
    "def forProp(x_data, m=3, w=[0]):\n",
    "    #if running for first time, initialize W^1 to small random non-zero values, so that tanh(w^Tx) is close to 0\n",
    "    #initialize so weights match up with number of neurons in the hidden layer\n",
    "    if len(w) < 2:\n",
    "        w_bot = []\n",
    "        w_mid = []\n",
    "        w_top = []\n",
    "        for i in range(0,m-1):\n",
    "            w_top.append(0.0004)\n",
    "            w_mid.append(-0.0002/x_data[0])\n",
    "            w_bot.append(-0.0001/x_data[1])\n",
    "        w.append([w_top, w_mid, w_bot])\n",
    "\n",
    "    #set x for layer 0 (input layer)\n",
    "    x = [[1, x_data[0], x_data[1]]]\n",
    "    s = [[0]]\n",
    "    for l in range(1,3):\n",
    "        #calculate s for each layer\n",
    "        s.append(np.dot(np.array(w[l]).T, np.array(x[l-1])))\n",
    "        \n",
    "        #use tanh activation function to obtain x, and add 1 in front representing bias neuron if not at last layer\n",
    "        next_x = np.tanh(s[l]).tolist()\n",
    "        if l != 2:\n",
    "            next_x.insert(0,1)\n",
    "        x.append(next_x)\n",
    "        \n",
    "        #initialize W^2 if first time running\n",
    "        if(len(w)<3):\n",
    "            next_w = []\n",
    "            for i in range(0, m):\n",
    "                if i == 0:\n",
    "                    next_w.append(((m+1)*0.0001)/x[l][i])\n",
    "                else:\n",
    "                    next_w.append(((m-i)*(-0.0001))/x[l][i])\n",
    "            w.append(next_w)\n",
    "\n",
    "    return s, x, w\n",
    "\n",
    "#Backpropagation to compute sensitivities d^l\n",
    "def backProp(x_data, y_data, m=3, w = [0]):\n",
    "    #get s, x, and w (if not initialized) from forward propagation\n",
    "    s, x, w = forProp(x_data, m, w)\n",
    "\n",
    "    d = [0,0,0]\n",
    "    \n",
    "    #calculate d^L\n",
    "    d[2] = 2*(x[2] - y_data)*(1-x[2]*x[2])\n",
    "\n",
    "    #calculate the derivative of the activation function used in back prop for layer L\n",
    "    x_b = x[1][1:]\n",
    "    tpsl = [1 - x_b * x_b for x_b,x_b in zip(x_b,x_b)]\n",
    "\n",
    "    #calculate the back-prop \"input\" to the hidden layer (multiply weight and sensitivity of layer in front)\n",
    "    w_b = w[2][1:]\n",
    "    right = [a*d[2] for a in w_b]\n",
    "    \n",
    "    #get the sensitivity value of the hidden layer\n",
    "    d[1] = [tpsl*right for tpsl,right in zip(tpsl,right)]\n",
    "    \n",
    "    return x,d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python library for Vedic Math sutras.  Includes the addition sutra used in this experiment. \n",
    "#Full credit goes to https://github.com/techmoksha/vedic-py\n",
    "\n",
    "# %load vedic.py\n",
    "from itertools import chain\n",
    "from math import pow\n",
    "\n",
    "\n",
    "class VedicNumber:\n",
    "\n",
    "\tdef __init__(self, num):\n",
    "\t\tif isinstance(num, int):\n",
    "\t\t\tnum = str(num)\n",
    "\t\tself.num = num\n",
    "\n",
    "\tdef __add__(self, other):\n",
    "\t\treturn Ops.add([self, other])\n",
    "\n",
    "\tdef __mul__(self, other):\n",
    "\t\treturn Ops.multiply(self, other)\n",
    "\n",
    "\tdef __sub__(self, other):\n",
    "\t\treturn Ops.subtract(self, other)\n",
    "\n",
    "\tdef __pow__(self, power, modulo=None):\n",
    "\t\treturn Ops.pow(self, power)\n",
    "\n",
    "\tdef __str__(self):\n",
    "\t\treturn self.num\n",
    "\n",
    "\n",
    "class Ops(object):\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef leftpad_zeroes(string, num):\n",
    "\t\t\"\"\"\n",
    "\t\tLeft pad a string with number of 0s = num\n",
    "\t\t:param string: String to pad\n",
    "\t\t:param num: Number of 0s to prepend\n",
    "\t\t:return:\n",
    "\t\t\"\"\"\n",
    "\t\toutput = ['0' for i in range(0, num)]\n",
    "\t\toutput = \"\".join(output)\n",
    "\t\treturn output + string\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef rightpad_zeroes(string, num):\n",
    "\t\t\"\"\"\n",
    "\t\tRight pad a string with number of 0s = num\n",
    "\t\t:param string: String to pad\n",
    "\t\t:param num: Number of 0s to append\n",
    "\t\t:return:\n",
    "\t\t\"\"\"\n",
    "\t\toutput = ['0' for i in range(0, num)]\n",
    "\t\toutput = \"\".join(output)\n",
    "\t\treturn string + output\n",
    "\n",
    "\t@staticmethod\n",
    "\t# TODO handle negative numbers\n",
    "\tdef add(nums):\n",
    "\t\t\"\"\"\n",
    "\t\tPerforms addition of all numbers based on vedic addition sutra\n",
    "\t\t:param nums : Array of numbers to be added. Each number can be string or int or #VedicNumber\n",
    "\t\t:return: Result of addition as a #VedicNumber\n",
    "\t\t\"\"\"\n",
    "\t\t# Get digits in number Convert to string\n",
    "\t\tnums = list(map(lambda num: str(num) if isinstance(num, VedicNumber) or isinstance(num, int) else num, nums))\n",
    "\t\t# Get length of biggest number\n",
    "\t\tmax_len = max([len(num) for num in nums])\n",
    "\t\t# Left pad where required\n",
    "\t\tnums = list(map(lambda num: Ops.leftpad_zeroes(num, max_len - len(num)), nums))\n",
    "\n",
    "\t\t# First one is added by default since at least one digit will be present\n",
    "\t\tpart1 = str(sum([int(num[0]) for num in nums]))\n",
    "\t\tmain_stack = list()\n",
    "\t\t# Append every character separately\n",
    "\t\t[main_stack.append(s) for s in part1]\n",
    "\n",
    "\t\tfor idx in range(1, max_len):\n",
    "\t\t\t# Add x[0] with y[0], x[1] with y[1] and so on while combining\n",
    "\t\t\tpart2 = sum([int(num[idx]) for num in nums])\n",
    "\t\t\t# Convert back to string\n",
    "\t\t\tpart2 = str(part2)\n",
    "\t\t\tif len(part2) == 1:\n",
    "\t\t\t\t# Append it to part 1 (Combine op)\n",
    "\t\t\t\tmain_stack.append(part2)\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Add result to last digit of part 1 with carry from part2(Combine op)\n",
    "\t\t\t\tres = part2\n",
    "\t\t\t\tresidual_stack = list()\n",
    "\t\t\t\tif len(res) == 1:\n",
    "\t\t\t\t\tresidual_stack.append(part2[-1])\n",
    "\t\t\t\t# Till res is a single digit we need to recurse\n",
    "\t\t\t\twhile len(res) > 1:\n",
    "\t\t\t\t\tpart1 = main_stack.pop()\n",
    "\t\t\t\t\tres = str(int(part1) + int(part2[0]))\n",
    "\t\t\t\t\tresidual_stack.append(part2[-1])\n",
    "\t\t\t\t\tif len(res) > 1:\n",
    "\t\t\t\t\t\tpart2 = res\n",
    "\t\t\t\tmain_stack.append(str(res))\n",
    "\t\t\t\t# Append residual stack\n",
    "\t\t\t\tmain_stack = list(chain(main_stack, residual_stack))\n",
    "\t\t\t\tresidual_stack = None\n",
    "\t\treturn VedicNumber(\"\".join(main_stack))\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef subtract(x, y):\n",
    "\t\t\"\"\"\n",
    "\t\tPerforms subtraction of y from x based on vedic subtraction sutra\n",
    "\t\t:param x : Larger number. Can be string or int or #VedicNumber\n",
    "\t\t:param y : Smaller number. Can be string or int or #VedicNumber\n",
    "\t\t:return: Result of subtraction as #VedicNumber\n",
    "\t\t\"\"\"\n",
    "\t\tif isinstance(x, int) or isinstance(x, VedicNumber):\n",
    "\t\t\tx = str(x)\n",
    "\t\tif isinstance(y, int) or isinstance(y, VedicNumber):\n",
    "\t\t\ty = str(y)\n",
    "\t\tmax_len = max(len(x), len(y))\n",
    "\t\tx = Ops.leftpad_zeroes(x, max_len - len(x))\n",
    "\t\ty = Ops.leftpad_zeroes(y, max_len - len(y))\n",
    "\n",
    "\t\tmain_stack = list()\n",
    "\t\tfound_conseq_digit = False\n",
    "\t\tinconseq_zeroes = 0\n",
    "\t\tmain_stack.append(str(int(x[0]) - int(y[0])))\n",
    "\n",
    "\t\tfor idx in range(1, max_len):\n",
    "\t\t\tnum1 = int(x[idx])\n",
    "\t\t\tnum2 = int(y[idx])\n",
    "\n",
    "\t\t\tif num1 < num2:\n",
    "\t\t\t\t# Pop off the earlier number\n",
    "\t\t\t\ttop = main_stack.pop()\n",
    "\t\t\t\t# Reduce the previous number\n",
    "\t\t\t\ttop = int(top) - 1\n",
    "\t\t\t\tmain_stack.append(str(top))\n",
    "\t\t\t\tcorrection_stack = list()\n",
    "\n",
    "\t\t\t\twhile top < 0:\n",
    "\t\t\t\t\t# Need to apply correction by adding negative number to 10\n",
    "\t\t\t\t\t# Pop off the top element and reduce by 1\n",
    "\t\t\t\t\ttop = main_stack.pop()\n",
    "\t\t\t\t\tcorrection = 10 + int(top)\n",
    "\t\t\t\t\t# Since correction is applied, 1 has to be deducted from new top\n",
    "\t\t\t\t\ttop = main_stack.pop()\n",
    "\t\t\t\t\ttop = int(top) - 1\n",
    "\t\t\t\t\tmain_stack.append(str(top))\n",
    "\t\t\t\t\tcorrection_stack.append(str(correction))\n",
    "\t\t\t\tmain_stack = list(chain(main_stack, correction_stack))\n",
    "\t\t\t\tcorrection_stack = None\n",
    "\t\t\t\t# Add 10 to num1\n",
    "\t\t\t\tnum1 += 10\n",
    "\t\t\tif found_conseq_digit is not True:\n",
    "\t\t\t\t# Check top element\n",
    "\t\t\t\ttop_most = main_stack[-1]\n",
    "\t\t\t\tif top_most == '0':\n",
    "\t\t\t\t\tinconseq_zeroes += 1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tfound_conseq_digit = True\n",
    "\t\t\tmain_stack.append(str(num1 - num2))\n",
    "\t\treturn VedicNumber(\"\".join(main_stack[inconseq_zeroes:]))\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef multiply(x, y):\n",
    "\t\t\"\"\"\n",
    "\t\tPerforms multiplication of x and y based on vedic general multiplication sutra\n",
    "\t\t:param x : Can be string int or #VedicNumber\n",
    "\t\t:param y : Can be string int or #VedicNumber\n",
    "\t\t:return: Result of multiplication as #VedicNumber\n",
    "\t\t\"\"\"\n",
    "\t\tif isinstance(x, int) or isinstance(x, VedicNumber):\n",
    "\t\t\tx = str(x)\n",
    "\t\tif isinstance(y, int) or isinstance(y, VedicNumber):\n",
    "\t\t\ty = str(y)\n",
    "\t\tmax_len = max(len(x), len(y))\n",
    "\t\tx = Ops.leftpad_zeroes(x, max_len - len(x))\n",
    "\t\ty = Ops.leftpad_zeroes(y, max_len - len(y))\n",
    "\n",
    "\t\t# Results of individual cross multiples\n",
    "\t\texecution_dict = Ops.perform_mult(x, y, max_len)\n",
    "\t\t# Reduce to get final result\n",
    "\t\treturn Ops.reduce(execution_dict)\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef perform_mult(x, y, max_len):\n",
    "\t\t# Number of steps will be 2 * num_digits - 1\n",
    "\t\tnum_steps = (2 * max_len) - 1\n",
    "\t\texecution_dict = dict()\n",
    "\n",
    "\t\t# Steps are symmetrical on either side of halfway mark\n",
    "\t\tfor idx in range(0, (num_steps >> 1) + 1):\n",
    "\t\t\texec_result_lhs = 0\n",
    "\t\t\texec_result_rhs = 0\n",
    "\t\t\tfor i in range(0, idx + 1):\n",
    "\t\t\t\texec_result_lhs += int(x[max_len - 1 - i]) * int(y[max_len - 1 - idx + i])\n",
    "\t\t\t\texec_result_rhs += int(x[i]) * int(y[idx - i])\n",
    "\t\t\texecution_dict[idx + 1] = exec_result_lhs\n",
    "\t\t\texecution_dict[num_steps - idx] = exec_result_rhs\n",
    "\n",
    "\t\treturn execution_dict\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef reduce(execution_dict):\n",
    "\t\t# print(execution_dict)\n",
    "\t\t# Final output stack\n",
    "\t\tresult_stack = []\n",
    "\t\tcarry = 0\n",
    "\n",
    "\t\tkeys = execution_dict.keys()\n",
    "\t\tfor i in range(1, len(keys) + 1):\n",
    "\t\t\ttop = execution_dict[i]\n",
    "\t\t\t# Add carry to it if present\n",
    "\t\t\ttop = str(int(top) + int(carry))\n",
    "\t\t\t# Reset carry\n",
    "\t\t\tcarry = 0\n",
    "\t\t\tif len(top) > 1:\n",
    "\t\t\t\tresult_stack.append(top[-1])\n",
    "\t\t\t\t# Push other part to carry\n",
    "\t\t\t\tcarry = top[:-1]\n",
    "\t\t\telse:\n",
    "\t\t\t\tresult_stack.append(top)\n",
    "\t\t# If any carry remains we need to push that as well\n",
    "\t\tif carry != 0:\n",
    "\t\t\tresult_stack.append(carry)\n",
    "\t\toutput = []\n",
    "\t\tfound_consequent_digit = False\n",
    "\n",
    "\t\twhile len(result_stack) > 0:\n",
    "\t\t\ttop = result_stack.pop()\n",
    "\t\t\t# Do not append inconsequential zeroes\n",
    "\t\t\tif int(top) > 0:\n",
    "\t\t\t\tfound_consequent_digit = True\n",
    "\t\t\tif found_consequent_digit:\n",
    "\t\t\t\toutput.append(top)\n",
    "\t\treturn VedicNumber(\"\".join(output))\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef fact(num):\n",
    "\t\tresult = VedicNumber(2)\n",
    "\t\tfor i in range(3, num + 1):\n",
    "\t\t\tresult *= VedicNumber(i)\n",
    "\t\treturn result\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef duplex(num):\n",
    "\t\tif isinstance(num, int) or isinstance(num, VedicNumber):\n",
    "\t\t\tnum = str(num)\n",
    "\t\t# Convert to constituent digits\n",
    "\t\tnum_digits = list(num)\n",
    "\t\tnum_digits = list(map(lambda digit: int(digit), num_digits))\n",
    "\t\tlength = len(num_digits)\n",
    "\t\tduplex = 0\n",
    "\t\tif length % 2 != 0:\n",
    "\t\t\t# Duplex is calculated as m ** 2 + 2 * a * b for odd digit numbers\n",
    "\t\t\tduplex = int(pow(num_digits[int(length / 2)], 2))\n",
    "\t\tduplex += 2 * sum([num_digits[i] * num_digits[length - 1 - i] for i in range(0, int(length / 2))])\n",
    "\t\treturn duplex\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef pow(num, power):\n",
    "\t\tif power == 2:\n",
    "\t\t\treturn Ops.sq(num)\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef sq(num):\n",
    "\t\t\"\"\"\n",
    "\t\tPerforms square of this number based on vedic square sutra\n",
    "\t\t:return: Result of square as #VedicNumber\n",
    "\t\t\"\"\"\n",
    "\t\tif isinstance(num, int) or isinstance(num, VedicNumber):\n",
    "\t\t\tnum = str(num)\n",
    "\t\tlength = len(num)\n",
    "\t\tduplexes = dict()\n",
    "\t\tfor i in range(1, length + 1):\n",
    "\t\t\tduplexes[(2 * length) - i] = Ops.duplex(num[0:i])\n",
    "\t\t\tduplexes[i] = Ops.duplex(num[length - i:length])\n",
    "\t\t# Reduce the duplex dict to single number\n",
    "\t\treturn Ops.reduce(duplexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Descent Normal implementation\n",
    "\n",
    "\n",
    "def gD(D, m=10, w = [0]):\n",
    "    #initialize E_in, G\n",
    "    E_in = 0\n",
    "    \n",
    "    #G initialized specifically to correspond to shape of this neural network\n",
    "    G = [0,[0,0,0],0]\n",
    "    \n",
    "    \n",
    "    for n in range(0, len(D)):\n",
    "        #get x values from forward prop and sensitivities d from backProp (calling backProp calls both sequentially)\n",
    "        x, d = backProp(D[n][0:2], D[n][2], m, w)\n",
    "        \n",
    "        #using sign function on output layer to determine E_in\n",
    "        if (x[2]>0 and D[n][2]<0) or (x[2]<0 and D[n][2]>0):\n",
    "            E_in = E_in+1\n",
    "\n",
    "        for l in range(1, 3):\n",
    "            Gx = np.multiply(np.array(x[l-1]).reshape(-1,1), np.array(d[l]).reshape(1,-1)).tolist()\n",
    "\n",
    "            #we have 2 units (not including bias) at the input layer and m units in the hidden layer.  \n",
    "            #Thus W[1] will have 3 lists containing m-1 weights each.  To add the gradient, we have to \n",
    "            #explicitly shape our gradient similarly which the following code does\n",
    "            if l == 1:     \n",
    "                #if this is the first data point in this iteration, our G[1] does not contain 3 lists yet\n",
    "                if type(G[l][0]) != list:\n",
    "                    #specialized Python syntax to add lists w/o errors\n",
    "                    #accounts for 3 lists in the first layer\n",
    "                    for sp in range(0,3):     \n",
    "                        G[l][sp] = [G[l][sp] + (1/len(D))*g_new for g_new in Gx[sp]]\n",
    "                else:\n",
    "                    #specialized Python syntax to add lists w/o errors\n",
    "                    #accounts for 3 lists in the first layer\n",
    "                    for sp in range(0,3):     \n",
    "                        G[l][sp] = [g_old + (1/len(D))*g_new for g_old, g_new in zip(G[l][sp],Gx[sp])]\n",
    "            else:\n",
    "                #if we are in layer 2, W[2] is a single list of m weights.  We use the following\n",
    "                #itertools library to concatenate the Gx[2] values into a single list\n",
    "                Gx = list(itertools.chain.from_iterable(Gx))\n",
    "                \n",
    "                #same procedure as above\n",
    "                if type(G[l]) != list:\n",
    "                    G[l] = [G[l] + (1/len(D))*g_new for g_new in Gx]\n",
    "                else:\n",
    "                    G[l] = [g_old + (1/len(D))*g_new for g_old, g_new in zip(G[l],Gx)]\n",
    "    E_in = E_in/len(D)\n",
    "    return E_in, G, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Descent Vedic implementation\n",
    "import math  \n",
    "\n",
    "\n",
    "def gDV(D, m=10, w = [0]):\n",
    "    #initialize E_in, G\n",
    "    E_in = 0\n",
    "    \n",
    "    #G initialized specifically to correspond to shape of this neural network\n",
    "    G = [VedicNumber(0),[VedicNumber(0),VedicNumber(0),VedicNumber(0)],VedicNumber(0)]\n",
    "\n",
    "    \n",
    "    for n in range(0, len(D)):\n",
    "        #get x values from forward prop and sensitivities d from backProp (calling backProp calls both sequentially)\n",
    "        x, d = backProp(D[n][0:2], D[n][2], m, w)\n",
    "        \n",
    "        #using sign function on output layer to determine E_in\n",
    "        if (x[2]>0 and D[n][2]<0) or (x[2]<0 and D[n][2]>0):\n",
    "            E_in = E_in+1\n",
    "\n",
    "        for l in range(1, 3):\n",
    "            Gx = np.multiply(np.array(x[l-1]).reshape(-1,1), np.array(d[l]).reshape(1,-1)).tolist()\n",
    "\n",
    "            #Vedic Number library has some bugs and limitations.  We modify gradient descent to implement it as far\n",
    "            #as possible\n",
    "            \n",
    "            #due to limitations of Vedic Number library, we can't add non-Vedic types with Vedic types. Hence, \n",
    "            #for the purposes of a proof of concept, we skip updating layer 1 of the gradients\n",
    "            if l == 1:     \n",
    "                continue;\n",
    "\n",
    "            else:\n",
    "                #if we are in layer 2, W[2] is a single list of m weights.  We use the following\n",
    "                #itertools library to concatenate the Gx[2] values into a single list\n",
    "                Gx = list(itertools.chain.from_iterable(Gx))\n",
    "                \n",
    "                #if this is the first data point in this iteration, our G[1] does not contain a lists yet\n",
    "                if type(G[l]) != list:\n",
    "                    #VEDIC ADDITION BEING USED\n",
    "                    print('Vedic addition being used!')\n",
    "                    G[l] = [G[l] + VedicNumber(abs(math.floor((1/len(D))*g_new))) for g_new in Gx]\n",
    "\n",
    "\n",
    "    E_in = E_in/len(D)\n",
    "    return E_in, G, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Descent Placebo implementation: matching Vedic version without using the Vedic Number library\n",
    "def gDP(D, m=10, w = [0]):\n",
    "    #initialize E_in, G\n",
    "    E_in = 0\n",
    "    \n",
    "    #G initialized specifically to correspond to shape of this neural network\n",
    "    G = [0,[0,0,0],0]\n",
    "    \n",
    "    for n in range(0, len(D)):\n",
    "        #get x values from forward prop and sensitivities d from backProp (calling backProp calls both sequentially)\n",
    "        x, d = backProp(D[n][0:2], D[n][2], m, w)\n",
    "        \n",
    "        #using sign function on output layer to determine E_in\n",
    "        if (x[2]>0 and D[n][2]<0) or (x[2]<0 and D[n][2]>0):\n",
    "            E_in = E_in+1\n",
    "\n",
    "        for l in range(1, 3):\n",
    "            Gx = np.multiply(np.array(x[l-1]).reshape(-1,1), np.array(d[l]).reshape(1,-1)).tolist()\n",
    "            \n",
    "            #matching modified GD in Vedic version above\n",
    "            if l == 1:     \n",
    "                continue;\n",
    "            else:\n",
    "                #if we are in layer 2, W[2] is a single list of m weights.  We use the following\n",
    "                #itertools library to concatenate the Gx[2] values into a single list\n",
    "                Gx = list(itertools.chain.from_iterable(Gx))\n",
    "                \n",
    "                #if this is the first data point in this iteration, our G[1] does not contain a lists yet\n",
    "                if type(G[l]) != list:\n",
    "                    G[l] = [G[l] + abs(math.floor((1/len(D))*g_new)) for g_new in Gx]\n",
    "    E_in = E_in/len(D)\n",
    "    return E_in, G, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "NORMAL\n",
      "CPU times: user 100 ms, sys: 13 ms, total: 113 ms\n",
      "Wall time: 102 ms\n",
      "89.1 ms  6.91 ms per loop (mean  std. dev. of 2 runs, 5 loops each)\n",
      "peak memory: 192.31 MiB, increment: 0.00 MiB\n",
      "\n",
      "\n",
      "\n",
      "VEDIC\n",
      "Vedic addition being used!\n",
      "CPU times: user 82.2 ms, sys: 9.27 ms, total: 91.5 ms\n",
      "Wall time: 83.3 ms\n",
      "Vedic addition being used!\n",
      "Vedic addition being used!\n",
      "Vedic addition being used!\n",
      "Vedic addition being used!\n",
      "Vedic addition being used!\n",
      "Vedic addition being used!\n",
      "Vedic addition being used!\n",
      "Vedic addition being used!\n",
      "Vedic addition being used!\n",
      "Vedic addition being used!\n",
      "77.2 ms  696 s per loop (mean  std. dev. of 2 runs, 5 loops each)\n",
      "Vedic addition being used!\n",
      "Vedic addition being used!\n",
      "peak memory: 192.32 MiB, increment: 0.00 MiB\n",
      "\n",
      "\n",
      "\n",
      "CONTROL\n",
      "CPU times: user 86.9 ms, sys: 12 ms, total: 98.9 ms\n",
      "Wall time: 88.1 ms\n",
      "69.4 ms  5.98 ms per loop (mean  std. dev. of 2 runs, 5 loops each)\n",
      "peak memory: 192.32 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "print(\"NORMAL\")\n",
    "%time gD(nnD[::-1], 10, [0])\n",
    "\n",
    "%timeit -r 2 -n 5 gD(nnD[::-1], 10, [0])\n",
    "\n",
    "%memit gD(nnD[::-1], 10, [0])\n",
    "print('\\n\\n')\n",
    "\n",
    "\n",
    "print(\"VEDIC\")\n",
    "%time gDV(nnD[::-1], 10, [0])\n",
    "\n",
    "%timeit -r 2 -n 5 gDV(nnD[::-1], 10, [0])\n",
    "\n",
    "\n",
    "%memit gDV(nnD[::-1], 10, [0])\n",
    "print('\\n\\n')\n",
    "\n",
    "\n",
    "\n",
    "print(\"CONTROL\")\n",
    "\n",
    "%time gDP(nnD[::-1], 10, [0])\n",
    "\n",
    "%timeit -r 2 -n 5 gDP(nnD[::-1], 10, [0])\n",
    "\n",
    "%memit gDP(nnD[::-1], 10, [0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
